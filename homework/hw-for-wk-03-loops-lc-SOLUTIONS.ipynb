{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz4lidEcC-wu"
   },
   "source": [
    "# Homework for Week 3\n",
    "\n",
    "The goal for this homework is to see the relevant journalistic uses for what we learned in class in week 4.\n",
    "\n",
    "1. Using the power of automation for iterate through tedious, but important tasks.\n",
    "2. Tapping Python to iterate through calculations. In a few weeks, you'll be doing this on millions of rows.\n",
    "3. Allowing us to slow down how fast our code runs to avoid detection or being blocked when we start scraping websites!\n",
    "4. Facilitating how we take a larger dataset and to subset it to useful targetted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Counter\n",
    "* Build a counter that counts from 2 to 10, but only even numbers.\n",
    "* Print the counter numbers in statement that reads: \"The even number is [whatever the even number is]\".\n",
    "* Once it reaches 10, it should print \"Done counting from 2 to 10 even numbers!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The even number is 2\n",
      "The even number is 4\n",
      "The even number is 6\n",
      "The even number is 8\n",
      "The even number is 10\n",
      "Done counting from 2 to 10 even numbers!\n"
     ]
    }
   ],
   "source": [
    "## build here:\n",
    "\n",
    "counter = 0\n",
    "while counter < 10:\n",
    "    counter += 2\n",
    "    print(f\"The even number is {counter}\")\n",
    "print(f\"Done counting from 2 to 10 even numbers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a counter with a timer\n",
    "* Add a timer to the previous code so it runs every 3 to 15 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The even number is 2. Snoozing for 5 seconds.\n",
      "The even number is 4. Snoozing for 11 seconds.\n",
      "The even number is 6. Snoozing for 4 seconds.\n",
      "The even number is 8. Snoozing for 10 seconds.\n",
      "The even number is 10. Snoozing for 11 seconds.\n",
      "The even number is 12. Snoozing for 9 seconds.\n",
      "Done counting from 2 to 10 even numbers!\n"
     ]
    }
   ],
   "source": [
    "## build here:\n",
    "\n",
    "import time\n",
    "from random import randrange\n",
    "counter = 0\n",
    "while counter < 12:\n",
    "    counter += 2\n",
    "    delay = randrange(3,15)\n",
    "    print(f\"The even number is {counter}. Snoozing for {delay} seconds.\")\n",
    "    time.sleep(delay)\n",
    "print(f\"Done counting from 2 to 10 even numbers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEXSVGi2C-w4"
   },
   "source": [
    "## 3.  Combine different data points together \n",
    "\n",
    "#### You scrape some URLs and place them in a list called myURLS (provided below):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mQwOrDIWC-w4"
   },
   "outputs": [],
   "source": [
    "## run this cell to activate the list\n",
    "myURLS = [\n",
    "    'great-unique-data-1.html',\n",
    "    'great-unique-data-2.html',\n",
    "    'great-unique-data-3.html',\n",
    "    'great-unique-data-4.html',\n",
    "    'great-unique-data-5.html',\n",
    "    'great-unique-data-6.html',\n",
    "    'great-unique-data-7.html',\n",
    "    'great-unique-data-8.html',\n",
    "    'great-unique-data-9.html',\n",
    "    'great-unique-data-10.html',\n",
    "    'great-unique-data-11.html',\n",
    "    'great-unique-data-12.html',\n",
    "    'great-unique-data-13.html',\n",
    "    'great-unique-data-14.html',\n",
    "    'great-unique-data-15.html'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGrsmmioC-w4",
    "outputId": "daf42c56-696e-45c5-daec-967ea4801db2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great-unique-data-1.html',\n",
       " 'great-unique-data-2.html',\n",
       " 'great-unique-data-3.html',\n",
       " 'great-unique-data-4.html',\n",
       " 'great-unique-data-5.html',\n",
       " 'great-unique-data-6.html',\n",
       " 'great-unique-data-7.html',\n",
       " 'great-unique-data-8.html',\n",
       " 'great-unique-data-9.html',\n",
       " 'great-unique-data-10.html',\n",
       " 'great-unique-data-11.html',\n",
       " 'great-unique-data-12.html',\n",
       " 'great-unique-data-13.html',\n",
       " 'great-unique-data-14.html',\n",
       " 'great-unique-data-15.html']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CALL myURLS to check it out\n",
    "myURLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W4WZ9-_C-w5"
   },
   "source": [
    "### * You realize that these URLs are missing the base of \"http://www.importantsite.com/\"\n",
    "### * Use a ```for loop``` to join the base URL to every partial URL in your list.\n",
    "### * Print each FULL URL\n",
    "It should look like: ```\"http://www.importantsite.com/great-unique-data-14.html``` but with unique numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFqX3JypC-w5",
    "outputId": "7322e6a3-c720-455b-e9fe-965e185f51bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.importantsite.com/great-unique-data-1.html\n",
      "http://www.importantsite.com/great-unique-data-2.html\n",
      "http://www.importantsite.com/great-unique-data-3.html\n",
      "http://www.importantsite.com/great-unique-data-4.html\n",
      "http://www.importantsite.com/great-unique-data-5.html\n",
      "http://www.importantsite.com/great-unique-data-6.html\n",
      "http://www.importantsite.com/great-unique-data-7.html\n",
      "http://www.importantsite.com/great-unique-data-8.html\n",
      "http://www.importantsite.com/great-unique-data-9.html\n",
      "http://www.importantsite.com/great-unique-data-10.html\n",
      "http://www.importantsite.com/great-unique-data-11.html\n",
      "http://www.importantsite.com/great-unique-data-12.html\n",
      "http://www.importantsite.com/great-unique-data-13.html\n",
      "http://www.importantsite.com/great-unique-data-14.html\n",
      "http://www.importantsite.com/great-unique-data-15.html\n"
     ]
    }
   ],
   "source": [
    "## build here:\n",
    "\n",
    "baseURL= \"http://www.importantsite.com/\"\n",
    "for each_url in myURLS:\n",
    "    full_url = baseURL + each_url\n",
    "    print(full_url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-DNZj4OC-w5",
    "outputId": "d6a7b497-56fb-47bd-aed1-4f9cd19ae2a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great-unique-data-1.html',\n",
       " 'great-unique-data-2.html',\n",
       " 'great-unique-data-3.html',\n",
       " 'great-unique-data-4.html',\n",
       " 'great-unique-data-5.html',\n",
       " 'great-unique-data-6.html',\n",
       " 'great-unique-data-7.html',\n",
       " 'great-unique-data-8.html',\n",
       " 'great-unique-data-9.html',\n",
       " 'great-unique-data-10.html',\n",
       " 'great-unique-data-11.html',\n",
       " 'great-unique-data-12.html',\n",
       " 'great-unique-data-13.html',\n",
       " 'great-unique-data-14.html',\n",
       " 'great-unique-data-15.html']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## call myURLS.\n",
    "## do they have the full url?\n",
    "myURLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fM6-d1hXC-w5"
   },
   "source": [
    "## 4. Update myURLS and store full URLS in a new list\n",
    "\n",
    "#### Instead of just printing the joined URLs, create a new list called ```full_URLS``` that holds the full URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vggh0aYAC-w5",
    "outputId": "7e1f46d1-0b1c-4784-c838-798bea161370"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.importantsite.com/great-unique-data-1.html',\n",
       " 'http://www.importantsite.com/great-unique-data-2.html',\n",
       " 'http://www.importantsite.com/great-unique-data-3.html',\n",
       " 'http://www.importantsite.com/great-unique-data-4.html',\n",
       " 'http://www.importantsite.com/great-unique-data-5.html',\n",
       " 'http://www.importantsite.com/great-unique-data-6.html',\n",
       " 'http://www.importantsite.com/great-unique-data-7.html',\n",
       " 'http://www.importantsite.com/great-unique-data-8.html',\n",
       " 'http://www.importantsite.com/great-unique-data-9.html',\n",
       " 'http://www.importantsite.com/great-unique-data-10.html',\n",
       " 'http://www.importantsite.com/great-unique-data-11.html',\n",
       " 'http://www.importantsite.com/great-unique-data-12.html',\n",
       " 'http://www.importantsite.com/great-unique-data-13.html',\n",
       " 'http://www.importantsite.com/great-unique-data-14.html',\n",
       " 'http://www.importantsite.com/great-unique-data-15.html']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build here:\n",
    "baseURL= \"http://www.importantsite.com/\"\n",
    "full_URLS = []\n",
    "for myURL in myURLS:\n",
    "    full_URLS.append(baseURL+myURL)\n",
    "full_URLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. You have a long list of toxins. Run the next cell to pull the list into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxins = [\n",
    "        \"Recombinant Bovine Growth Hormone\", \n",
    "        \"Butylated Hydroxyanisole\", \n",
    "        \"Sodium Aluminum Sulphate\",\n",
    "        \"Potassium Aluminum Sulphate\",\n",
    "        \"Sodium Nitrite\",\n",
    "        \"Polycyclic Aromatic Hydrocarbons\",\n",
    "        \"Dioxins\",\n",
    "        \"Heterocyclic Amines\",\n",
    "        \"Butylated Hydroxytoluene\",\n",
    "        \"Polyvinyl Chloride\",\n",
    "        \"PVC\",\n",
    "        \"Perfluorooctanoic Acid\",\n",
    "        \"PFOA\",\n",
    "        \"Triclosan\",\n",
    "        \"Bisphenol-A\",\n",
    "        \"BPA\",\n",
    "        \"Formaldehyde\",\n",
    "        \"Naphthalene\",\n",
    "        \"Asbestos\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You realize that the toxins from \"Polyvinyl Chloride\" to the end of the list are hormone disruptors.\n",
    "\n",
    "Programmatically create a new list using List Comprehension called ```hormone_inhibitors``` that includes all the chemicals from \"Polyvinyl Chloride\" to \"Asbestos\".\n",
    "\n",
    "- Do NOT manually count to figure out the index position of \"Polyvinyl Chloride\".\n",
    "- Do NOT manually type out a new list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### answer here (create more cells if necessary)\n",
    "## we can figure out the position for \"Polyvinyl Chloride\"\n",
    "toxins.index(\"Polyvinyl Chloride\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Polyvinyl Chloride',\n",
       " 'PVC',\n",
       " 'Perfluorooctanoic Acid',\n",
       " 'PFOA',\n",
       " 'Triclosan',\n",
       " 'Bisphenol-A',\n",
       " 'BPA',\n",
       " 'Formaldehyde',\n",
       " 'Naphthalene',\n",
       " 'Asbestos']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## in one line we can call the index position all the way to the end.\n",
    "hormone_inhibitors = toxins[toxins.index(\"Polyvinyl Chloride\"):]\n",
    "hormone_inhibitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using a ```for loop``` create a list called ```sodium_fl``` that captures only the toxins that have the word ```sodium``` in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sodium aluminum sulphate', 'sodium nitrite']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build it here\n",
    "\n",
    "sodium_fl = []\n",
    "\n",
    "for toxin in toxins:\n",
    "    toxin = toxin.lower()\n",
    "    if \"sodium\" in toxin:\n",
    "        sodium_fl.append(toxin) \n",
    "    \n",
    "sodium_fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using a ```list comprehension``` create a list called ```sodium_lc``` that captures only the toxins that have the word ```sodium``` in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_IubbqlC-w4",
    "outputId": "b680eae8-4ed3-4e0f-bf4b-f96ca0a17f46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sodium Aluminum Sulphate', 'Sodium Nitrite']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build here: \n",
    "\n",
    "sodium_lc = [toxin for toxin in toxins if \"sodium\" in toxin.lower()]\n",
    "sodium_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ```for loop``` Calculations\n",
    "\n",
    "Run the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this cell\n",
    "monthly_rent_2022 = [3500, 2700, 1200, 5000, 3500, 2000, 4300, 3400, 3900 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this fast gentrifying neighborhood, the monthly rent will increase by 27.8 percent for 2023.  Using a ```for loop``` create a new list called ```monthly_rent_2023_fl``` that shows the increased rent rounded to ZERO decimal places. \n",
    "\n",
    "Do the calculation programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4473, 3451, 1534, 6390, 4473, 2556, 5495, 4345, 4984]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### answer here (create more cells if necessary)\n",
    "rent_increase = 1.278\n",
    "monthly_rent_2023_fl = []\n",
    "for rent in monthly_rent_2022:\n",
    "    updated_rent = round(rent * rent_increase)\n",
    "    monthly_rent_2023_fl.append(updated_rent)\n",
    "\n",
    "monthly_rent_2023_fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ```list comprehension``` Calculation\n",
    "\n",
    "The same scenario as above but now create a list called ```monthly_rent_2023_lc``` using ```list comprehension```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4473, 3451, 1534, 6390, 4473, 2556, 5495, 4345, 4984]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### answer here (create more cells if necessary)\n",
    "\n",
    "monthly_rent_2023_lc = [round(rent * rent_increase) for rent in monthly_rent_2022]\n",
    "monthly_rent_2023_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ```zip``` it\n",
    "\n",
    "You scrape a website and end up with the lists below.\n",
    "\n",
    "Use both the methods we covered in class to create a ```df``` and then a ```csv``` file from these lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The content you scraped is now in the following lists:\n",
    "\n",
    "source_files = ['7681804Q.pdf', '7543447R.pdf', '7864672J.pdf', '8073426Q.pdf', '7909756P.pdf', '7749758M.pdf', '7917101M.pdf', '7880385Y.pdf', '7958281Z.pdf', '7836909K.pdf', '7891371L.pdf', '7096205N.pdf']\n",
    "\n",
    "date_appeals = ['10-Jan-18', '31-May-17', '20-Nov-18', '6-Dec-19', '12-Feb-19', '1-May-18', '25-Feb-19', '18-Dec-18', '8-May-19', '2-Oct-18', '8-Jan-19', '6-Aug-15']\n",
    "\n",
    "cognition_related = [False, True, False, False, True, False, False, True, True, True, False, False]\n",
    "\n",
    "positive_decisions = [False, True, True, False, False, True, True, True, True, True, False, True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A- Use the zip() into list of dictionaries method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here – create more cells as necessary\n",
    "## import pandas – needed to create df and export\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## declare empty list and for loop zip\n",
    "medicaid_decisions_dicts = []\n",
    "\n",
    "## for loop:\n",
    "for (date, cog, decision, source)\\\n",
    "in zip(date_appeals, cognition_related, positive_decisions, source_files):\n",
    "    medicaid_decisions_dicts.append({\n",
    "        \"appeal_date\": date,\n",
    "        \"cognition_related\": cog,\n",
    "        \"positive_decision\": decision,\n",
    "        \"source_file\": source\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'appeal_date': '10-Jan-18',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': False,\n",
       "  'source_file': '7681804Q.pdf'},\n",
       " {'appeal_date': '31-May-17',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': True,\n",
       "  'source_file': '7543447R.pdf'},\n",
       " {'appeal_date': '20-Nov-18',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': True,\n",
       "  'source_file': '7864672J.pdf'},\n",
       " {'appeal_date': '6-Dec-19',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': False,\n",
       "  'source_file': '8073426Q.pdf'},\n",
       " {'appeal_date': '12-Feb-19',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': False,\n",
       "  'source_file': '7909756P.pdf'},\n",
       " {'appeal_date': '1-May-18',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': True,\n",
       "  'source_file': '7749758M.pdf'},\n",
       " {'appeal_date': '25-Feb-19',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': True,\n",
       "  'source_file': '7917101M.pdf'},\n",
       " {'appeal_date': '18-Dec-18',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': True,\n",
       "  'source_file': '7880385Y.pdf'},\n",
       " {'appeal_date': '8-May-19',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': True,\n",
       "  'source_file': '7958281Z.pdf'},\n",
       " {'appeal_date': '2-Oct-18',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': True,\n",
       "  'source_file': '7836909K.pdf'},\n",
       " {'appeal_date': '8-Jan-19',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': False,\n",
       "  'source_file': '7891371L.pdf'},\n",
       " {'appeal_date': '6-Aug-15',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': True,\n",
       "  'source_file': '7096205N.pdf'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## show list of dictionaries\n",
    "medicaid_decisions_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appeal_date</th>\n",
       "      <th>cognition_related</th>\n",
       "      <th>positive_decision</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-Jan-18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7681804Q.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31-May-17</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7543447R.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20-Nov-18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7864672J.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6-Dec-19</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8073426Q.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12-Feb-19</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>7909756P.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1-May-18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7749758M.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25-Feb-19</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7917101M.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18-Dec-18</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7880385Y.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8-May-19</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7958281Z.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2-Oct-18</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7836909K.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8-Jan-19</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7891371L.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6-Aug-15</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7096205N.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appeal_date  cognition_related  positive_decision   source_file\n",
       "0    10-Jan-18              False              False  7681804Q.pdf\n",
       "1    31-May-17               True               True  7543447R.pdf\n",
       "2    20-Nov-18              False               True  7864672J.pdf\n",
       "3     6-Dec-19              False              False  8073426Q.pdf\n",
       "4    12-Feb-19               True              False  7909756P.pdf\n",
       "5     1-May-18              False               True  7749758M.pdf\n",
       "6    25-Feb-19              False               True  7917101M.pdf\n",
       "7    18-Dec-18               True               True  7880385Y.pdf\n",
       "8     8-May-19               True               True  7958281Z.pdf\n",
       "9     2-Oct-18               True               True  7836909K.pdf\n",
       "10    8-Jan-19              False              False  7891371L.pdf\n",
       "11    6-Aug-15              False               True  7096205N.pdf"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert list of dicts to df\n",
    "\n",
    "df = pd.DataFrame(medicaid_decisions_fl)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export to csv\n",
    "df.to_csv(\"medicaid_decisions_dicts.csv\", encoding = \"UTF-8\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B- Use the zip() into list of tuples method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here – create more cells as necessary\n",
    "## declare empty list and zip as list of tuples\n",
    "medicaid_decisions_tuples = []\n",
    "\n",
    "## zip into tuples:\n",
    "for item in zip(date_appeals, cognition_related, positive_decisions, source_files):\n",
    "    medicaid_decisions_tuples.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10-Jan-18', False, False, '7681804Q.pdf'),\n",
       " ('31-May-17', True, True, '7543447R.pdf'),\n",
       " ('20-Nov-18', False, True, '7864672J.pdf'),\n",
       " ('6-Dec-19', False, False, '8073426Q.pdf'),\n",
       " ('12-Feb-19', True, False, '7909756P.pdf'),\n",
       " ('1-May-18', False, True, '7749758M.pdf'),\n",
       " ('25-Feb-19', False, True, '7917101M.pdf'),\n",
       " ('18-Dec-18', True, True, '7880385Y.pdf'),\n",
       " ('8-May-19', True, True, '7958281Z.pdf'),\n",
       " ('2-Oct-18', True, True, '7836909K.pdf'),\n",
       " ('8-Jan-19', False, False, '7891371L.pdf'),\n",
       " ('6-Aug-15', False, True, '7096205N.pdf')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## call our tuples list\n",
    "medicaid_decisions_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_appeals</th>\n",
       "      <th>cognition_related</th>\n",
       "      <th>positive_decision</th>\n",
       "      <th>source_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-Jan-18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7681804Q.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31-May-17</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7543447R.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20-Nov-18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7864672J.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6-Dec-19</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8073426Q.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12-Feb-19</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>7909756P.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1-May-18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7749758M.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25-Feb-19</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7917101M.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18-Dec-18</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7880385Y.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8-May-19</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7958281Z.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2-Oct-18</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7836909K.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8-Jan-19</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7891371L.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6-Aug-15</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7096205N.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_appeals  cognition_related  positive_decision  source_files\n",
       "0     10-Jan-18              False              False  7681804Q.pdf\n",
       "1     31-May-17               True               True  7543447R.pdf\n",
       "2     20-Nov-18              False               True  7864672J.pdf\n",
       "3      6-Dec-19              False              False  8073426Q.pdf\n",
       "4     12-Feb-19               True              False  7909756P.pdf\n",
       "5      1-May-18              False               True  7749758M.pdf\n",
       "6     25-Feb-19              False               True  7917101M.pdf\n",
       "7     18-Dec-18               True               True  7880385Y.pdf\n",
       "8      8-May-19               True               True  7958281Z.pdf\n",
       "9      2-Oct-18               True               True  7836909K.pdf\n",
       "10     8-Jan-19              False              False  7891371L.pdf\n",
       "11     6-Aug-15              False               True  7096205N.pdf"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## export to a pandas dataframe\n",
    "df = pd.DataFrame(medicaid_decisions_tuples)\n",
    "## name the columns\n",
    "df.columns = [\"date_appeals\", \"cognition_related\",\n",
    "              \"positive_decision\", \"source_files\"]\n",
    "\n",
    "## call df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export to csv\n",
    "df.to_csv(\"medicaid_decisions_tuples.csv\", encoding = \"UTF-8\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You just harnessed the power of Python to accomplish the following tasks that are critical foundational skills to become an advanced data journalist:\n",
    "\n",
    "1. Using the power of automation for iterate through tedious, but important tasks.\n",
    "2. Tapping Python to iterate through calculations. In a few weeks, you'll be doing this on millions of rows.\n",
    "3. Allowing us to slow down how fast our code runs to avoid detection or being blocked when we start scraping websites!\n",
    "4. Facilitating how we take a larger dataset and to subset it to useful targetted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-for-week-3-SOLUTIONS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
