{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QwY_aPURcTp"
   },
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61gyS0yfh2i7"
   },
   "source": [
    "### The problem?\n",
    "\n",
    "- Endless amounts of unstructured data found in emails, tweets, letters, memos, etc.\n",
    "- Even in transcripts\n",
    "- How can we make sense of all this data?\n",
    "- How can we 'easily' find relevant information for our reporting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFFYKXh0h2i8"
   },
   "source": [
    "### The solution?\n",
    "- Computer programming to process all that text using **natural language processing**!\n",
    "- <a href=\"https://machinelearningmastery.com/natural-language-processing/\">Learn more</a> about the complexity and the history of NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oR26_2FPh2i8"
   },
   "source": [
    "### Journalism examples\n",
    "\n",
    "- <a href=\"http://doctors.ajc.com/part_1_license_to_betray/\">License to betray</a> – Finding word stems and roots to uncover abuse. (<a href=\"http://doctors.ajc.com/about_this_investigation/?ecmp=doctorssexabuse_microsite_stories\">More info</a>)\n",
    "- <a href=\"https://www.revealnews.org/article/federal-judges-rulings-favored-companies-in-which-he-owned-stock/\">Federal judge’s rulings favored companies in which he owned stock</a> – Finding all stock owned by judges in disclosure forms and comparing to caseloads.\n",
    "- <a href=\"https://www.latimes.com/local/cityhall/la-me-crime-stats-20151015-story.html\">LAPD underreported serious assaults, skewing crime stats for 8 years</a> – Text classification analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGwqeUHzh2i9"
   },
   "source": [
    "### The tools\n",
    "\n",
    "- Spacy v. NLTK\n",
    "- NLTK launched in 2001, Spacy in 2015\n",
    "- NLTK is now bloated and complex, requiring many steps to deal with many changes etc.\n",
    "- Spacy is lean and modern, and can compute some text 4x to 20x faster than NLTK.\n",
    "- Spacy does **nearly** everything that NLTK does, but better.\n",
    "- NLTK, however, is still the library of choice for sentiment analysis.\n",
    "\n",
    "However, sentiment analysis in journalism can be problematic. Be extra wary of NLP's use for news analysis. AI can easily misinterpret the sentiment in this sentence:\n",
    "\n",
    "\"It is a great movie if you have the taste and sensibilities of a five-year-old boy.\"\n",
    "\n",
    "It's best to stick to the following types of analysis:\n",
    "\n",
    "- Mentions of a word or concept (who said something...when and how many times?)\n",
    "- Frequency of target terms or topics (how often were keywords used in speeches, transcripts, etc)\n",
    "- Words over time (a timeline that shows frequency of words over time)\n",
    "- Missing words (really a flip of words over time to show how people stopped using certain concepts or terms)\n",
    "- Key people, places, companies (identify proper nouns and places for reporting)\n",
    "- Comparisons (for example financial disclosures over time...which stocks were added or removed over the years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYgC0y5Yh2i9"
   },
   "source": [
    "# Working with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ly8WKOVPYV9-"
   },
   "source": [
    "## Step 1. Install Spacy\n",
    "\n",
    "If this first time ever using spacy on this computer, you must first do either the ```!conda install``` or ```!pip install```:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TURN OFF FOR COLAB\n",
    "Run for ANACONDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TURN OFF FOR ANACONDA\n",
    "Run for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-S6NorkRcTu",
    "outputId": "432fd1da-15fb-4994-8d93-6a578e741e75"
   },
   "outputs": [],
   "source": [
    "## COLAB pip install\n",
    "# !pip install -U spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdUvDJNDRcTy"
   },
   "outputs": [],
   "source": [
    "## import libary.\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8xpwtwPRcT1"
   },
   "source": [
    "#### Which language model is best for you?\n",
    "<a href=\"https://spacy.io/usage/models\">https://spacy.io/usage/models</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcPisnnlRcT1"
   },
   "source": [
    "## Step 2. Install language model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANACONDA ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge spacy-model-en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLAB ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9L770hGkZePT",
    "outputId": "c59f0a1a-f29d-4411-8f7f-ef4dc8610d50"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1FId7V5h2jA"
   },
   "outputs": [],
   "source": [
    "## import that language model\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVP20HngRcT8"
   },
   "source": [
    "### Place English libary into a ```nlp``` pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqDMPPHxRcT8"
   },
   "outputs": [],
   "source": [
    "## build nlp pipeline (a function will tokenize, parse and ner for us)\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0G92vbFFFlU",
    "outputId": "ee754cc8-5592-4357-82a9-7a0b8bf77a28"
   },
   "outputs": [],
   "source": [
    "## what type of object is nlp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJyaMU2Ah2jB"
   },
   "source": [
    "## Step 3. Text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yy8E66pRRcT5"
   },
   "outputs": [],
   "source": [
    "### Sample English text:\n",
    "text = u'''\\\n",
    "On May 10, 2011, Microsoft announced its acquisition of Skype Technologies, \\\n",
    "creator of the VoIP service Skype, for $8.5 billion. \\\n",
    "Microsoft is headquartered near Seattle Washington while Skype remains in Palo Alto, California. \\\n",
    "Sandeep Junnarkar got this from Wikipedia. \\\n",
    "But he'd rather head to Paris, France to see the Mona Lisa at the Louvre. \\\n",
    "The Hudson River should really be called by its original native name, Mahicantuck, which means \"the river that flows two ways.\" \\\n",
    "Mahicantuck flows for 315 miles to the Atlantic Ocean from its source at Mt. Mercy, the tallest peak in New York state.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "8SFy7IZwh2jC",
    "outputId": "4cdad441-bea1-4728-c2b1-60ad92be9044"
   },
   "outputs": [],
   "source": [
    "## CALL the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PRINT the tex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZQdKpPKRcT_"
   },
   "source": [
    "### Tokenize our text\n",
    "\n",
    "- Tokenizing is always the first step in text analysis. \n",
    "- It breaks all text into isolated but related units (including spaces, symbols, punctuation, numbers, words etc.)\n",
    "- However, it retains the connection between all the words, sentences, and paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHeDiZnRRcUA"
   },
   "outputs": [],
   "source": [
    "## let's run the nlp function and create a spacy doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BCaBvHuQshj_",
    "outputId": "86c5b711-7a2b-47d7-92a4-54dab6567d0b"
   },
   "outputs": [],
   "source": [
    "## CALL doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1aV38l6RcUC",
    "outputId": "a8f36c45-3316-4a00-d261-88d0f729b501"
   },
   "outputs": [],
   "source": [
    "## what type of data is it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zJ_bNTzRcUF",
    "outputId": "328e5fb8-bd6c-4c64-bab2-5094e309ef53"
   },
   "outputs": [],
   "source": [
    "## show each token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmNHn1Ukh2jE"
   },
   "source": [
    "### Parts of speech\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65Yi1Plih2jF",
    "outputId": "baff8391-2bf5-43c6-e03f-49343593022a"
   },
   "outputs": [],
   "source": [
    "## print all parts of speech words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzYn5aS2h2jF"
   },
   "source": [
    "### Step 4. Named Entity Recognition (NER)\n",
    "\n",
    "#### Spacy easily returns the words that matter to us like names of companies, people, places, art works, numbers, etc.\n",
    "\n",
    "- ```.ents``` ------------> Finds all entities in doc spacy object.\n",
    "\n",
    "- ```ent.text``` ------------> The actual text.\n",
    "\n",
    "- ```ent.label``` ------------> A numeric code for the entity.\n",
    "\n",
    "- ```ent.label_``` ------------> The word's entity category.\n",
    "\n",
    "- ```spacy.explain(ent.label_)``` ---------> A description of the category.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "47lc7chb2eiM",
    "outputId": "7d999440-d8ed-4eb7-f97a-12446db07d4e"
   },
   "outputs": [],
   "source": [
    "### call text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2gJS6j2Lh2jF",
    "outputId": "4c8a9710-9aeb-4239-ccd5-bbe49caa3106"
   },
   "outputs": [],
   "source": [
    "## find all entities\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEmZLDFPh2jF",
    "outputId": "8ce33e50-ff5d-45d3-a102-63ff3b9da1aa"
   },
   "outputs": [],
   "source": [
    "## find all entities with their label\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ix0MJB1Gh2jF",
    "outputId": "7628ec35-dd84-4780-bbed-6ee9cc85711e"
   },
   "outputs": [],
   "source": [
    "## find all entities with their label and label descriptors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uIQMKlkh2jF"
   },
   "source": [
    "### Create a CSV that holds all the organizations/companies in a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WgRr6kwHh2jG",
    "outputId": "fc02aeab-16f7-4377-a98c-81b6764636ef"
   },
   "outputs": [],
   "source": [
    "## find all entities and place in a list using list comprehension\n",
    "\n",
    "## find all entities\n",
    " ## find all entity labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yr3l8f83h2jG",
    "outputId": "1172b3a8-8f70-4212-db78-c534f6fc74e5"
   },
   "outputs": [],
   "source": [
    "### Turn the two lists into a dictionary using a for loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxDJMiXoh2jG",
    "outputId": "2560f088-2b02-4732-9d90-12e9c1b538ad"
   },
   "outputs": [],
   "source": [
    "### Turn the two lists into a dictionary using \n",
    "### dictionary comprehension within list comprehension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdxYdoDph2jG",
    "outputId": "4f1fb1e3-f9ae-4301-8dac-163e567095ad"
   },
   "outputs": [],
   "source": [
    "## the previous lists hold all entities. \n",
    "## let's narrow them down to the orgs/companies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dPDO4O3Ih2jG",
    "outputId": "beaed38d-468a-4b2b-f446-43df3d2e574a"
   },
   "outputs": [],
   "source": [
    "## What data types are these?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_234MDAh2jG"
   },
   "source": [
    "### Let's deduplicate\n",
    "\n",
    "We could wait and use unique in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9d6xXl6h2jH",
    "outputId": "59b4ac9e-93dc-49b9-88c1-f0d8b4da480d"
   },
   "outputs": [],
   "source": [
    "## deduplicate a dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOU3h3BMh2jH"
   },
   "outputs": [],
   "source": [
    "## import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z1wNDD-Ah2jH",
    "outputId": "da5a5236-b19e-46e5-8d71-b02f30be82e4"
   },
   "outputs": [],
   "source": [
    "# ## use pandas to write to csv file\n",
    "filename = \"test-entities-1.csv\"\n",
    "df = pd.DataFrame(all_orgs) ## we turn our life dict into a dataframe which we're call df\n",
    "df.to_csv(filename, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_aeW2aMRcUK"
   },
   "outputs": [],
   "source": [
    "\n",
    "## function to find entities\n",
    "def show_entities(my_text):\n",
    "  '''\n",
    "  my_text must be a spacy doc tokenized object; already run through nlp pipeline\n",
    "\n",
    "  '''\n",
    "  each_token = \"Token\"\n",
    "  entity_type = \"Entity\"\n",
    "  entity_def = \"Entity Defined\"\n",
    "  print(f\"{each_token:{30}}{entity_type:{15}}{entity_def}\")\n",
    "  if my_text.ents:\n",
    "      for word in my_text.ents:\n",
    "          print(f\"{word.text:{30}} {word.label_:{15}} {str(spacy.explain(word.label_))}\")\n",
    "  else:\n",
    "      print(\"There are no entities in this text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTNWHsd_RxW9",
    "outputId": "efd2695b-9fbf-45d1-faff-44a781e277c5"
   },
   "outputs": [],
   "source": [
    "## show entities in my english sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specialized function to capture entity types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create function to return list of dictionaries of entities and entity labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test it to find orgs\n",
    "info_list = ner(doc, \"ORG\")\n",
    "info_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nkzIHWcRcUM"
   },
   "source": [
    "## Install other languages\n",
    "#### Other languages can be found at https://spacy.io/usage/models\n",
    "\n",
    "#### Disclaimer: Language models are built by open source communities. English and German are the most advanced language models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC8HluMERcUN"
   },
   "source": [
    "### Spanish language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANACONDA ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda update -n base -c conda-forge conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLAB ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuHEEuUDSXPa",
    "outputId": "37e69b3b-ff03-444e-ba3e-5fc5dc97eeb6"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmjeb7LYRcUQ"
   },
   "outputs": [],
   "source": [
    "## import the library and create nlp pipleline\n",
    "import es_core_news_sm\n",
    "nlp = es_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEfgJHvERcUW"
   },
   "outputs": [],
   "source": [
    "### Sample Spanish Text (sorry!)\n",
    "stext = \"\"\"\n",
    "El 10 de mayo de 2011, Microsoft anunció la adquisición de Skype Technologies,\\\n",
    "creador del servicio de VoIP Skype, por 8.500 millones de dólares. Microsoft tiene\\\n",
    "su sede cerca de Seattle, Washington, mientras que Skype permanece en Palo Alto,\\\n",
    "California. Sandeep Junnarkar obtuvo esto de Wikipedia. Pero preferiría ir a París,\\\n",
    "Francia, a ver la Mona Lisa en el Louvre. El río Hudson realmente debería llamarse por\\\n",
    "su nombre nativo original, Mahicantuck, que significa \"el río\\\n",
    "que fluye en dos direcciones\". Mahicantuck fluye por 315 millas hacia el Océano Atlántico\\\n",
    "desde su origen en Mt. Mercy, el pico más alto del estado de Nueva York.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eg767ypnRcUY"
   },
   "outputs": [],
   "source": [
    "## tokenize and show parts of speech for each token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dt67pTWYGmVf",
    "outputId": "99c61097-bb98-4256-91a6-b03e30d1969d"
   },
   "outputs": [],
   "source": [
    "## show the tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onKjJi8ORcUa",
    "outputId": "20cdf61d-87a8-4ad6-dd28-8d80ac6f1897"
   },
   "outputs": [],
   "source": [
    "## show entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import file(s)\n",
    "\n",
    "Unzip and place <a href=\"https://drive.google.com/file/d/1mWpUK819KlOjsLPe4l1c5dsmXqX2QqVS/view?usp=share_link\">this folder</a> at the same level as this notebook. It contains two files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import package\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import demo text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show specific entities in my demo_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## look for all people via list comprehension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## package to flattend\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## flatten list of list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next week:\n",
    "\n",
    "- Word frequency\n",
    "- Context around words\n",
    "- Surprise ending?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [
    "fvkdsW79RcUN"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
