{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QwY_aPURcTp"
   },
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61gyS0yfh2i7"
   },
   "source": [
    "### The problem?\n",
    "\n",
    "- Endless amounts of unstructured data found in emails, tweets, letters, memos, etc.\n",
    "- Even in transcripts\n",
    "- How can we make sense of all this data?\n",
    "- How can we 'easily' find relevant information for our reporting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFFYKXh0h2i8"
   },
   "source": [
    "### The solution?\n",
    "- Computer programming to process all that text using **natural language processing**!\n",
    "- <a href=\"https://machinelearningmastery.com/natural-language-processing/\">Learn more</a> about the complexity and the history of NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oR26_2FPh2i8"
   },
   "source": [
    "### Journalism examples\n",
    "\n",
    "- <a href=\"http://doctors.ajc.com/part_1_license_to_betray/\">License to betray</a> – Finding word stems and roots to uncover abuse. (<a href=\"http://doctors.ajc.com/about_this_investigation/?ecmp=doctorssexabuse_microsite_stories\">More info</a>)\n",
    "- <a href=\"https://www.revealnews.org/article/federal-judges-rulings-favored-companies-in-which-he-owned-stock/\">Federal judge’s rulings favored companies in which he owned stock</a> – Finding all stock owned by judges in disclosure forms and comparing to caseloads.\n",
    "- <a href=\"https://www.latimes.com/local/cityhall/la-me-crime-stats-20151015-story.html\">LAPD underreported serious assaults, skewing crime stats for 8 years</a> – Text classification analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGwqeUHzh2i9"
   },
   "source": [
    "### The tools\n",
    "\n",
    "- Spacy v. NLTK\n",
    "- NLTK launched in 2001, Spacy in 2015\n",
    "- NLTK is now bloated and complex, requiring many steps to deal with many changes etc.\n",
    "- Spacy is lean and modern, and can compute some text 4x to 20x faster than NLTK.\n",
    "- Spacy does **nearly** everything that NLTK does, but better.\n",
    "- NLTK, however, is still the library of choice for sentiment analysis.\n",
    "\n",
    "However, sentiment analysis in journalism can be problematic. Be extra wary of NLP's use for news analysis. AI can easily misinterpret the sentiment in this sentence:\n",
    "\n",
    "\"It is a great movie if you have the taste and sensibilities of a five-year-old boy.\"\n",
    "\n",
    "It's best to stick to the following types of analysis:\n",
    "\n",
    "- Mentions of a word or concept (who said something...when and how many times?)\n",
    "- Frequency of target terms or topics (how often were keywords used in speeches, transcripts, etc)\n",
    "- Words over time (a timeline that shows frequency of words over time)\n",
    "- Missing words (really a flip of words over time to show how people stopped using certain concepts or terms)\n",
    "- Key people, places, companies (identify proper nouns and places for reporting)\n",
    "- Comparisons (for example financial disclosures over time...which stocks were added or removed over the years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYgC0y5Yh2i9"
   },
   "source": [
    "# Working with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ly8WKOVPYV9-"
   },
   "source": [
    "## Step 1. Install Spacy\n",
    "\n",
    "If this first time ever using spacy on this computer, you must first do either the ```!conda install``` or ```!pip install```:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TURN OFF FOR COLAB\n",
    "Run for ANACONDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TURN OFF FOR ANACONDA\n",
    "Run for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-S6NorkRcTu",
    "outputId": "432fd1da-15fb-4994-8d93-6a578e741e75"
   },
   "outputs": [],
   "source": [
    "## COLAB pip install\n",
    "# !pip install -U spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdUvDJNDRcTy"
   },
   "outputs": [],
   "source": [
    "## import libary.\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8xpwtwPRcT1"
   },
   "source": [
    "#### Which language model is best for you?\n",
    "<a href=\"https://spacy.io/usage/models\">https://spacy.io/usage/models</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcPisnnlRcT1"
   },
   "source": [
    "## Step 2. Install language model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANACONDA ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge spacy-model-en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLAB ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9L770hGkZePT",
    "outputId": "c59f0a1a-f29d-4411-8f7f-ef4dc8610d50"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1FId7V5h2jA"
   },
   "outputs": [],
   "source": [
    "## import that language model\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVP20HngRcT8"
   },
   "source": [
    "### Place English libary into a ```nlp``` pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqDMPPHxRcT8"
   },
   "outputs": [],
   "source": [
    "## build nlp pipeline (a function will tokenize, parse and ner for us)\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0G92vbFFFlU",
    "outputId": "ee754cc8-5592-4357-82a9-7a0b8bf77a28"
   },
   "outputs": [],
   "source": [
    "## what type of object is nlp\n",
    "type(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJyaMU2Ah2jB"
   },
   "source": [
    "## Step 3. Text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "yy8E66pRRcT5"
   },
   "outputs": [],
   "source": [
    "### Sample English text:\n",
    "text = u'''\\\n",
    "On May 10, 2011, Microsoft announced its acquisition of Skype Technologies, \\\n",
    "creator of the VoIP service Skype, for $8.5 billion. \\\n",
    "Microsoft is headquartered near Seattle Washington while Skype remains in Palo Alto, California. \\\n",
    "Sandeep Junnarkar got this from Wikipedia. \\\n",
    "We're beaming you aboard Captain Kirk. Or should i call you William Shatner.\\\n",
    "But he'd rather head to Paris, France to see the Mona Lisa at the Louvre. \\\n",
    "The Hudson River should really be called by its original native name, Mahicantuck, which means \"the river that flows two ways.\" \\\n",
    "Mahicantuck flows for 315 miles to the Atlantic Ocean from its source at Mt. Mercy, the tallest peak in New York state.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "8SFy7IZwh2jC",
    "outputId": "4cdad441-bea1-4728-c2b1-60ad92be9044"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On May 10, 2011, Microsoft announced its acquisition of\\xa0Skype Technologies, creator of the\\xa0VoIP\\xa0service\\xa0Skype, for $8.5 billion. Microsoft is headquartered near Seattle Washington while Skype remains in Palo Alto, California. Sandeep Junnarkar got this from Wikipedia. We\\'re beaming you aboard Captain Kirk. Or should i call you William Shatner.But he\\'d rather head to Paris, France to see the Mona Lisa at the Louvre. The Hudson River should really be called by its original native name, Mahicantuck, which means \"the river that flows two ways.\" Mahicantuck flows for 315 miles to the Atlantic Ocean from its source at Mt. Mercy, the tallest peak in New York state.\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CALL the text\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On May 10, 2011, Microsoft announced its acquisition of Skype Technologies, creator of the VoIP service Skype, for $8.5 billion. Microsoft is headquartered near Seattle Washington while Skype remains in Palo Alto, California. Sandeep Junnarkar got this from Wikipedia. We're beaming you aboard Captain Kirk. Or should i call you William Shatner.But he'd rather head to Paris, France to see the Mona Lisa at the Louvre. The Hudson River should really be called by its original native name, Mahicantuck, which means \"the river that flows two ways.\" Mahicantuck flows for 315 miles to the Atlantic Ocean from its source at Mt. Mercy, the tallest peak in New York state.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## PRINT the tex\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZQdKpPKRcT_"
   },
   "source": [
    "### Tokenize our text\n",
    "\n",
    "- Tokenizing is always the first step in text analysis. \n",
    "- It breaks all text into isolated but related units (including spaces, symbols, punctuation, numbers, words etc.)\n",
    "- However, it retains the connection between all the words, sentences, and paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "SHeDiZnRRcUA"
   },
   "outputs": [],
   "source": [
    "## let's run the nlp function and create a spacy doc\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BCaBvHuQshj_",
    "outputId": "86c5b711-7a2b-47d7-92a4-54dab6567d0b"
   },
   "outputs": [],
   "source": [
    "## CALL doc\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1aV38l6RcUC",
    "outputId": "a8f36c45-3316-4a00-d261-88d0f729b501"
   },
   "outputs": [],
   "source": [
    "## what type of data is it?\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zJ_bNTzRcUF",
    "outputId": "328e5fb8-bd6c-4c64-bab2-5094e309ef53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On\n",
      "***********\n",
      "May\n",
      "***********\n",
      "10\n",
      "***********\n",
      ",\n",
      "***********\n",
      "2011\n",
      "***********\n",
      ",\n",
      "***********\n",
      "Microsoft\n",
      "***********\n",
      "announced\n",
      "***********\n",
      "its\n",
      "***********\n",
      "acquisition\n",
      "***********\n",
      "of\n",
      "***********\n",
      " \n",
      "***********\n",
      "Skype\n",
      "***********\n",
      "Technologies\n",
      "***********\n",
      ",\n",
      "***********\n",
      "creator\n",
      "***********\n",
      "of\n",
      "***********\n",
      "the\n",
      "***********\n",
      " \n",
      "***********\n",
      "VoIP\n",
      "***********\n",
      " \n",
      "***********\n",
      "service\n",
      "***********\n",
      " \n",
      "***********\n",
      "Skype\n",
      "***********\n",
      ",\n",
      "***********\n",
      "for\n",
      "***********\n",
      "$\n",
      "***********\n",
      "8.5\n",
      "***********\n",
      "billion\n",
      "***********\n",
      ".\n",
      "***********\n",
      "Microsoft\n",
      "***********\n",
      "is\n",
      "***********\n",
      "headquartered\n",
      "***********\n",
      "near\n",
      "***********\n",
      "Seattle\n",
      "***********\n",
      "Washington\n",
      "***********\n",
      "while\n",
      "***********\n",
      "Skype\n",
      "***********\n",
      "remains\n",
      "***********\n",
      "in\n",
      "***********\n",
      "Palo\n",
      "***********\n",
      "Alto\n",
      "***********\n",
      ",\n",
      "***********\n",
      "California\n",
      "***********\n",
      ".\n",
      "***********\n",
      "Sandeep\n",
      "***********\n",
      "Junnarkar\n",
      "***********\n",
      "got\n",
      "***********\n",
      "this\n",
      "***********\n",
      "from\n",
      "***********\n",
      "Wikipedia\n",
      "***********\n",
      ".\n",
      "***********\n",
      "We\n",
      "***********\n",
      "'re\n",
      "***********\n",
      "beaming\n",
      "***********\n",
      "you\n",
      "***********\n",
      "aboard\n",
      "***********\n",
      "Captain\n",
      "***********\n",
      "Kirk\n",
      "***********\n",
      ".\n",
      "***********\n",
      "Or\n",
      "***********\n",
      "should\n",
      "***********\n",
      "i\n",
      "***********\n",
      "call\n",
      "***********\n",
      "you\n",
      "***********\n",
      "William\n",
      "***********\n",
      "Shatner\n",
      "***********\n",
      ".\n",
      "***********\n",
      "But\n",
      "***********\n",
      "he\n",
      "***********\n",
      "'d\n",
      "***********\n",
      "rather\n",
      "***********\n",
      "head\n",
      "***********\n",
      "to\n",
      "***********\n",
      "Paris\n",
      "***********\n",
      ",\n",
      "***********\n",
      "France\n",
      "***********\n",
      "to\n",
      "***********\n",
      "see\n",
      "***********\n",
      "the\n",
      "***********\n",
      "Mona\n",
      "***********\n",
      "Lisa\n",
      "***********\n",
      "at\n",
      "***********\n",
      "the\n",
      "***********\n",
      "Louvre\n",
      "***********\n",
      ".\n",
      "***********\n",
      "The\n",
      "***********\n",
      "Hudson\n",
      "***********\n",
      "River\n",
      "***********\n",
      "should\n",
      "***********\n",
      "really\n",
      "***********\n",
      "be\n",
      "***********\n",
      "called\n",
      "***********\n",
      "by\n",
      "***********\n",
      "its\n",
      "***********\n",
      "original\n",
      "***********\n",
      "native\n",
      "***********\n",
      "name\n",
      "***********\n",
      ",\n",
      "***********\n",
      "Mahicantuck\n",
      "***********\n",
      ",\n",
      "***********\n",
      "which\n",
      "***********\n",
      "means\n",
      "***********\n",
      "\"\n",
      "***********\n",
      "the\n",
      "***********\n",
      "river\n",
      "***********\n",
      "that\n",
      "***********\n",
      "flows\n",
      "***********\n",
      "two\n",
      "***********\n",
      "ways\n",
      "***********\n",
      ".\n",
      "***********\n",
      "\"\n",
      "***********\n",
      "Mahicantuck\n",
      "***********\n",
      "flows\n",
      "***********\n",
      "for\n",
      "***********\n",
      "315\n",
      "***********\n",
      "miles\n",
      "***********\n",
      "to\n",
      "***********\n",
      "the\n",
      "***********\n",
      "Atlantic\n",
      "***********\n",
      "Ocean\n",
      "***********\n",
      "from\n",
      "***********\n",
      "its\n",
      "***********\n",
      "source\n",
      "***********\n",
      "at\n",
      "***********\n",
      "Mt.\n",
      "***********\n",
      "Mercy\n",
      "***********\n",
      ",\n",
      "***********\n",
      "the\n",
      "***********\n",
      "tallest\n",
      "***********\n",
      "peak\n",
      "***********\n",
      "in\n",
      "***********\n",
      "New\n",
      "***********\n",
      "York\n",
      "***********\n",
      "state\n",
      "***********\n",
      ".\n",
      "***********\n",
      "\n",
      "\n",
      "***********\n"
     ]
    }
   ],
   "source": [
    "## show each token\n",
    "for token in doc:\n",
    "    print(token)\n",
    "    print(\"***********\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmNHn1Ukh2jE"
   },
   "source": [
    "### Parts of speech\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65Yi1Plih2jF",
    "outputId": "baff8391-2bf5-43c6-e03f-49343593022a"
   },
   "outputs": [],
   "source": [
    "## print all parts of speech words\n",
    "for token in doc:\n",
    "    print(f\"{token.text:{15}} {token.pos:{10}} {token.pos_:{5}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzYn5aS2h2jF"
   },
   "source": [
    "### Step 4. Named Entity Recognition (NER)\n",
    "\n",
    "#### Spacy easily returns the words that matter to us like names of companies, people, places, art works, numbers, etc.\n",
    "\n",
    "- ```.ents``` ------------> Finds all entities in doc spacy object.\n",
    "\n",
    "- ```ent.text``` ------------> The actual text.\n",
    "\n",
    "- ```ent.label``` ------------> A numeric code for the entity.\n",
    "\n",
    "- ```ent.label_``` ------------> The word's entity category.\n",
    "\n",
    "- ```spacy.explain(ent.label_)``` ---------> A description of the category.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "47lc7chb2eiM",
    "outputId": "7d999440-d8ed-4eb7-f97a-12446db07d4e"
   },
   "outputs": [],
   "source": [
    "### call text\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2gJS6j2Lh2jF",
    "outputId": "4c8a9710-9aeb-4239-ccd5-bbe49caa3106"
   },
   "outputs": [],
   "source": [
    "## find all entities\n",
    "for word in doc.ents:\n",
    "    print(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEmZLDFPh2jF",
    "outputId": "8ce33e50-ff5d-45d3-a102-63ff3b9da1aa"
   },
   "outputs": [],
   "source": [
    "## find all entities with their label\n",
    "\n",
    "for word in doc.ents:\n",
    "    print(f\"{word}------->{word.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ix0MJB1Gh2jF",
    "outputId": "7628ec35-dd84-4780-bbed-6ee9cc85711e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May 10, 2011------->DATE------>Absolute or relative dates or periods\n",
      "Microsoft------->ORG------>Companies, agencies, institutions, etc.\n",
      "Skype Technologies------->ORG------>Companies, agencies, institutions, etc.\n",
      "Skype------->ORG------>Companies, agencies, institutions, etc.\n",
      "$8.5 billion------->MONEY------>Monetary values, including unit\n",
      "Microsoft------->ORG------>Companies, agencies, institutions, etc.\n",
      "Seattle------->GPE------>Countries, cities, states\n",
      "Washington------->GPE------>Countries, cities, states\n",
      "Skype------->ORG------>Companies, agencies, institutions, etc.\n",
      "Palo Alto------->GPE------>Countries, cities, states\n",
      "California------->GPE------>Countries, cities, states\n",
      "Sandeep Junnarkar------->PERSON------>People, including fictional\n",
      "Wikipedia------->ORG------>Companies, agencies, institutions, etc.\n",
      "Kirk------->PERSON------>People, including fictional\n",
      "William Shatner------->PERSON------>People, including fictional\n",
      "Paris------->GPE------>Countries, cities, states\n",
      "France------->GPE------>Countries, cities, states\n",
      "the Mona Lisa------->WORK_OF_ART------>Titles of books, songs, etc.\n",
      "Louvre------->LOC------>Non-GPE locations, mountain ranges, bodies of water\n",
      "The Hudson River------->LOC------>Non-GPE locations, mountain ranges, bodies of water\n",
      "Mahicantuck------->ORG------>Companies, agencies, institutions, etc.\n",
      "two------->CARDINAL------>Numerals that do not fall under another type\n",
      "Mahicantuck------->WORK_OF_ART------>Titles of books, songs, etc.\n",
      "315 miles------->QUANTITY------>Measurements, as of weight or distance\n",
      "the Atlantic Ocean------->LOC------>Non-GPE locations, mountain ranges, bodies of water\n",
      "Mt. Mercy------->LOC------>Non-GPE locations, mountain ranges, bodies of water\n",
      "New York------->GPE------>Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "## find all entities with their label and label descriptors\n",
    "for word in doc.ents:\n",
    "    print(f\"{word}------->{word.label_}------>{spacy.explain(word.label_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uIQMKlkh2jF"
   },
   "source": [
    "### Create a CSV that holds all the organizations/companies in a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WgRr6kwHh2jG",
    "outputId": "fc02aeab-16f7-4377-a98c-81b6764636ef"
   },
   "outputs": [],
   "source": [
    "## find all entities and place in a list using list comprehension\n",
    "\n",
    "entities = [word.text for word in doc.ents]## find all entities\n",
    "ent_labels = [word.label_ for word in doc.ents]## find all entity labels\n",
    "\n",
    "# ent_labels\n",
    "# entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yr3l8f83h2jG",
    "outputId": "1172b3a8-8f70-4212-db78-c534f6fc74e5"
   },
   "outputs": [],
   "source": [
    "### Turn the two lists into a dictionary using a for loop\n",
    "my_entities_fl = []\n",
    "for (key, value) in zip(ent_labels, entities):\n",
    "    mydict = {key: value}\n",
    "    my_entities_fl.append(mydict)\n",
    "    \n",
    "my_entities_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxDJMiXoh2jG",
    "outputId": "2560f088-2b02-4732-9d90-12e9c1b538ad"
   },
   "outputs": [],
   "source": [
    "### Turn the two lists into a dictionary using \n",
    "### dictionary comprehension within list comprehension\n",
    "\n",
    "my_ents_lc = [{k:v} for (k, v) in zip(ent_labels, entities)]\n",
    "my_ents_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdxYdoDph2jG",
    "outputId": "4f1fb1e3-f9ae-4301-8dac-163e567095ad"
   },
   "outputs": [],
   "source": [
    "## the previous lists hold all entities. \n",
    "## let's narrow them down to the orgs/companies\n",
    "orgs_only = [{k:v} for (k, v) in zip(ent_labels, entities) if k == \"ORG\"]\n",
    "orgs_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dPDO4O3Ih2jG",
    "outputId": "beaed38d-468a-4b2b-f446-43df3d2e574a"
   },
   "outputs": [],
   "source": [
    "## What data types are these?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_234MDAh2jG"
   },
   "source": [
    "### Let's deduplicate\n",
    "\n",
    "We could wait and use unique in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9d6xXl6h2jH",
    "outputId": "59b4ac9e-93dc-49b9-88c1-f0d8b4da480d"
   },
   "outputs": [],
   "source": [
    "## deduplicate a dictionary\n",
    "# orgs_only = {frozenset(thing.items()) : thing for thing in orgs_only}.values()\n",
    "# list(orgs_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOU3h3BMh2jH"
   },
   "outputs": [],
   "source": [
    "## import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "R_aeW2aMRcUK"
   },
   "outputs": [],
   "source": [
    "\n",
    "## function to find entities\n",
    "## function to find entities\n",
    "def show_entities(my_text):\n",
    "  '''\n",
    "  my_text must be a spacy doc tokenized object; already run through nlp pipeline\n",
    "\n",
    "  '''\n",
    "  each_token = \"Token\"\n",
    "  entity_type = \"Entity\"\n",
    "  entity_def = \"Entity Defined\"\n",
    "  print(f\"{each_token:{30}}{entity_type:{15}}{entity_def}\")\n",
    "  if my_text.ents:\n",
    "      for word in my_text.ents:\n",
    "          print(f\"{word.text:{30}} {word.label_:{15}} {str(spacy.explain(word.label_))}\")\n",
    "  else:\n",
    "      print(\"There are no entities in this text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTNWHsd_RxW9",
    "outputId": "efd2695b-9fbf-45d1-faff-44a781e277c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token                         Entity         Entity Defined\n",
      "May 10, 2011                   DATE            Absolute or relative dates or periods\n",
      "Microsoft                      ORG             Companies, agencies, institutions, etc.\n",
      "Skype Technologies             ORG             Companies, agencies, institutions, etc.\n",
      "Skype                          ORG             Companies, agencies, institutions, etc.\n",
      "$8.5 billion                   MONEY           Monetary values, including unit\n",
      "Microsoft                      ORG             Companies, agencies, institutions, etc.\n",
      "Seattle                        GPE             Countries, cities, states\n",
      "Washington                     GPE             Countries, cities, states\n",
      "Skype                          ORG             Companies, agencies, institutions, etc.\n",
      "Palo Alto                      GPE             Countries, cities, states\n",
      "California                     GPE             Countries, cities, states\n",
      "Sandeep Junnarkar              PERSON          People, including fictional\n",
      "Wikipedia                      ORG             Companies, agencies, institutions, etc.\n",
      "Kirk                           PERSON          People, including fictional\n",
      "William Shatner                PERSON          People, including fictional\n",
      "Paris                          GPE             Countries, cities, states\n",
      "France                         GPE             Countries, cities, states\n",
      "the Mona Lisa                  WORK_OF_ART     Titles of books, songs, etc.\n",
      "Louvre                         LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "The Hudson River               LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "Mahicantuck                    ORG             Companies, agencies, institutions, etc.\n",
      "two                            CARDINAL        Numerals that do not fall under another type\n",
      "Mahicantuck                    WORK_OF_ART     Titles of books, songs, etc.\n",
      "315 miles                      QUANTITY        Measurements, as of weight or distance\n",
      "the Atlantic Ocean             LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "Mt. Mercy                      LOC             Non-GPE locations, mountain ranges, bodies of water\n",
      "New York                       GPE             Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "## show entities in my english sentence\n",
    "show_entities(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specialized function to capture entity types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create function to return list of dictionaries of entities and entity labels\n",
    "def find_ner(doc, type):\n",
    "    '''\n",
    "    doc: any text must be a spacy tokenized object;\n",
    "    doc: already run through nlp pipeline;\n",
    "    type: \"ORG\", \"PERSON\", \"DATE\", ETC. must be in quotes\n",
    "    '''\n",
    "    ent_labels = [token.label_ for token in doc.ents]\n",
    "    entities = [token.text for token in doc.ents]\n",
    "    return [{key:value} for (key, value) in zip(ent_labels, entities) if key == type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'GPE': 'Seattle'},\n",
       " {'GPE': 'Washington'},\n",
       " {'GPE': 'Palo Alto'},\n",
       " {'GPE': 'California'},\n",
       " {'GPE': 'Paris'},\n",
       " {'GPE': 'France'},\n",
       " {'GPE': 'New York'}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test it to find orgs\n",
    "info_list = find_ner(doc, \"GPE\")\n",
    "info_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nkzIHWcRcUM"
   },
   "source": [
    "## Install other languages\n",
    "#### Other languages can be found at https://spacy.io/usage/models\n",
    "\n",
    "#### Disclaimer: Language models are built by open source communities. English and German are the most advanced language models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC8HluMERcUN"
   },
   "source": [
    "### Spanish language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANACONDA ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda update -n base -c conda-forge conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLAB & ANACONDA ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuHEEuUDSXPa",
    "outputId": "37e69b3b-ff03-444e-ba3e-5fc5dc97eeb6"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmjeb7LYRcUQ"
   },
   "outputs": [],
   "source": [
    "## import the library and create nlp pipleline\n",
    "import es_core_news_sm\n",
    "nlp = es_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEfgJHvERcUW"
   },
   "outputs": [],
   "source": [
    "### Sample Spanish Text (sorry!)\n",
    "stext = \"\"\"\n",
    "El 10 de mayo de 2011, Microsoft anunció la adquisición de Skype Technologies,\\\n",
    "creador del servicio de VoIP Skype, por 8.500 millones de dólares. Microsoft tiene\\\n",
    "su sede cerca de Seattle, Washington, mientras que Skype permanece en Palo Alto,\\\n",
    "California. Sandeep Junnarkar obtuvo esto de Wikipedia. Pero preferiría ir a París,\\\n",
    "Francia, a ver la Mona Lisa en el Louvre. El río Hudson realmente debería llamarse por\\\n",
    "su nombre nativo original, Mahicantuck, que significa \"el río\\\n",
    "que fluye en dos direcciones\". Mahicantuck fluye por 315 millas hacia el Océano Atlántico\\\n",
    "desde su origen en Mt. Mercy, el pico más alto del estado de Nueva York.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eg767ypnRcUY"
   },
   "outputs": [],
   "source": [
    "## tokenize and show parts of speech for each token\n",
    "doc_s = nlp(stext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dt67pTWYGmVf",
    "outputId": "99c61097-bb98-4256-91a6-b03e30d1969d"
   },
   "outputs": [],
   "source": [
    "## show the tokens\n",
    "type(doc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onKjJi8ORcUa",
    "outputId": "20cdf61d-87a8-4ad6-dd28-8d80ac6f1897"
   },
   "outputs": [],
   "source": [
    "## show entities\n",
    "show_entities(doc_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import file(s)\n",
    "\n",
    "Unzip and place <a href=\"https://drive.google.com/file/d/1mWpUK819KlOjsLPe4l1c5dsmXqX2QqVS/view?usp=share_link\">this folder</a> at the same level as this notebook. It contains two files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import package\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nlp-files/biden-africa.txt', 'nlp-files/russia-oil.txt']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import demo text\n",
    "myfiles = glob.glob(\"nlp-files/*.txt\")\n",
    "myfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp-files/biden-africa.txt\n",
      "nlp-files/russia-oil.txt\n"
     ]
    }
   ],
   "source": [
    "## read the document\n",
    "all_text =[]\n",
    "for file in myfiles:\n",
    "    print(file)\n",
    "    with open(file, \"r\") as some_text:\n",
    "        demo_text = some_text.read()\n",
    "        doc = nlp(demo_text)\n",
    "        all_text.append(doc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## show entities\n",
    "show_entities(all_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show specific entities in my demo_text\n",
    "find_ner(all_text[0], \"PERSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'PERSON': 'Xi Jinping'},\n",
       "  {'PERSON': 'Biden'},\n",
       "  {'PERSON': 'Biden'},\n",
       "  {'PERSON': 'Biden'},\n",
       "  {'PERSON': 'Murithi Mutiga'},\n",
       "  {'PERSON': 'Macky Sall'},\n",
       "  {'PERSON': 'Barack Obama'},\n",
       "  {'PERSON': 'Obama'},\n",
       "  {'PERSON': 'Antony J. Blinken'},\n",
       "  {'PERSON': 'Biden'},\n",
       "  {'PERSON': 'Biden'},\n",
       "  {'PERSON': 'George W. Bush'},\n",
       "  {'PERSON': 'Obama'},\n",
       "  {'PERSON': 'Biden'},\n",
       "  {'PERSON': 'Judd Devermont'},\n",
       "  {'PERSON': 'Devermont'},\n",
       "  {'PERSON': 'Michelle D. Gavin'},\n",
       "  {'PERSON': 'Clinton'},\n",
       "  {'PERSON': 'Cameron Hudson'},\n",
       "  {'PERSON': 'Biden'},\n",
       "  {'PERSON': 'Abiji Mary Immaculate'},\n",
       "  {'PERSON': 'Sithembile Mbete'},\n",
       "  {'PERSON': 'Biden'}],\n",
       " [{'PERSON': 'Maciej Onoszko'},\n",
       "  {'PERSON': 'Slav Okov'},\n",
       "  {'PERSON': 'Vladimir Putin'},\n",
       "  {'PERSON': 'Putin'},\n",
       "  {'PERSON': 'Piotr Naimski'},\n",
       "  {'PERSON': 'Katja Yafimava'},\n",
       "  {'PERSON': 'Simone Tagliapietra'},\n",
       "  {'PERSON': 'Gazprombank'},\n",
       "  {'PERSON': 'Yafimava'},\n",
       "  {'PERSON': 'Piotr Skolimowski'},\n",
       "  {'PERSON': 'Piotr Bujnicki'},\n",
       "  {'PERSON': 'Ewa Krukowska'}]]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## look for all people via list comprehension\n",
    "all_people = [find_ner(token, \"PERSON\")for token in all_text]\n",
    "all_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## package to flattend\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'PERSON': 'Xi Jinping'},\n",
       " {'PERSON': 'Biden'},\n",
       " {'PERSON': 'Biden'},\n",
       " {'PERSON': 'Biden'},\n",
       " {'PERSON': 'Murithi Mutiga'},\n",
       " {'PERSON': 'Macky Sall'},\n",
       " {'PERSON': 'Barack Obama'},\n",
       " {'PERSON': 'Obama'},\n",
       " {'PERSON': 'Antony J. Blinken'},\n",
       " {'PERSON': 'Biden'},\n",
       " {'PERSON': 'Biden'},\n",
       " {'PERSON': 'George W. Bush'},\n",
       " {'PERSON': 'Obama'},\n",
       " {'PERSON': 'Biden'},\n",
       " {'PERSON': 'Judd Devermont'},\n",
       " {'PERSON': 'Devermont'},\n",
       " {'PERSON': 'Michelle D. Gavin'},\n",
       " {'PERSON': 'Clinton'},\n",
       " {'PERSON': 'Cameron Hudson'},\n",
       " {'PERSON': 'Biden'},\n",
       " {'PERSON': 'Abiji Mary Immaculate'},\n",
       " {'PERSON': 'Sithembile Mbete'},\n",
       " {'PERSON': 'Biden'},\n",
       " {'PERSON': 'Maciej Onoszko'},\n",
       " {'PERSON': 'Slav Okov'},\n",
       " {'PERSON': 'Vladimir Putin'},\n",
       " {'PERSON': 'Putin'},\n",
       " {'PERSON': 'Piotr Naimski'},\n",
       " {'PERSON': 'Katja Yafimava'},\n",
       " {'PERSON': 'Simone Tagliapietra'},\n",
       " {'PERSON': 'Gazprombank'},\n",
       " {'PERSON': 'Yafimava'},\n",
       " {'PERSON': 'Piotr Skolimowski'},\n",
       " {'PERSON': 'Piotr Bujnicki'},\n",
       " {'PERSON': 'Ewa Krukowska'}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## flatten list of list\n",
    "people_list = list(itertools.chain(*all_people))\n",
    "people_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next week:\n",
    "\n",
    "- Word frequency\n",
    "- Context around words\n",
    "- Any questions you may have..."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [
    "fvkdsW79RcUN"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
